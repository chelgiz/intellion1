import os

import requests
from bs4 import BeautifulSoup
from typing import List
import time
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("NewsFetcher")

# ‚úÖ RapidAPI Bing News
RAPID_API_KEY = os.getenv("RAPID_API_KEY")
HEADERS_BING = {
    "X-BingApis-SDK": "true",
    "X-RapidAPI-Key": RAPID_API_KEY,
    "X-RapidAPI-Host": "bing-news-search1.p.rapidapi.com"
}
BING_URL = "https://bing-news-search1.p.rapidapi.com/news/search"

# ‚úÖ Google fallback (HTML)
HEADERS_GOOGLE = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
}
GOOGLE_URL = "https://www.google.com/search?q={query}&tbm=nws&hl=en"


def fetch_news_bing(query: str, max_articles: int = 5) -> List[str]:
    try:
        params = {
            "q": query,
            "freshness": "Month",
            "textFormat": "Raw",
            "safeSearch": "Off",
            "count": max_articles,
            "mkt": "en-US"
        }
        response = requests.get(BING_URL, headers=HEADERS_BING, params=params, timeout=5)
        response.raise_for_status()
        data = response.json()
        articles = data.get("value", [])
        results = [article["name"] for article in articles if "name" in article]
        logger.info(f"üì∞ Bing: –Ω–∞–π–¥–µ–Ω–æ {len(results)} –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è '{query}'")
        return results
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Bing API –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª –¥–ª—è '{query}': {e}")
        return []


def fallback_google_news(query: str, max_articles: int = 5) -> List[str]:
    try:
        url = GOOGLE_URL.format(query=query.replace(" ", "+"))
        response = requests.get(url, headers=HEADERS_GOOGLE, timeout=5)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–¥–∏—Ä–µ–∫—Ç –∫ consent.google.com
        if "consent.google.com" in response.url:
            logger.warning(f"‚ö†Ô∏è Google —Ç—Ä–µ–±—É–µ—Ç —Å–æ–≥–ª–∞—Å–∏–µ –Ω–∞ cookies ‚Äî –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω –¥–ª—è '{query}'")
            return []

        soup = BeautifulSoup(response.text, "html.parser")
        results = []

        for g in soup.find_all("div", class_="BVG0Nb"):
            text = g.get_text()
            if text:
                results.append(text.strip())
            if len(results) >= max_articles:
                break

        logger.info(f"üì∞ Google fallback: –Ω–∞–π–¥–µ–Ω–æ {len(results)} –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è '{query}'")
        time.sleep(1.0)
        return results

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Google –¥–ª—è '{query}': {e}")
        return []


def get_news(player_name: str) -> List[str]:
    query = player_name.strip()
    news = fetch_news_bing(query)
    if not news:
        logger.info(f"üîÅ –ü—Ä–æ–±—É–µ–º Google-–ø–æ–∏—Å–∫ –¥–ª—è '{query}'")
        news = fallback_google_news(query)
    return news
